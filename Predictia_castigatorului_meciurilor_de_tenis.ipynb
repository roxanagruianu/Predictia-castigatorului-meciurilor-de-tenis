{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roxanagruianu/Predictia-castigatorului-meciurilor-de-tenis/blob/main/Predictia_castigatorului_meciurilor_de_tenis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictia castigatorului meciurilor de tenis"
      ],
      "metadata": {
        "id": "dLZMzLejG-r_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introducere"
      ],
      "metadata": {
        "id": "oLdgOineHDjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setul de date contine informatii detaliat despre meciurile de tenis ATP din perioada 2000-2025. Fiecare inregistrare reprezinta un meci si include informatii precum: numele turneului, data la care a avut loc meciul, tipul turneului, suprafata terenului, runda meciului din turneu, numarul de seturi necesare pentru casti, numele, locul in clasament, numarul de puncte ATP si cota de casti a jucatorilor, castigatorul si scorul meciului."
      ],
      "metadata": {
        "id": "DSWCtFU6HIoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obiecivul proiectului este de a construi modele predictive pentru a anticipa castigatorul meciurilor ATP utilizad mai multe metode ML: regresie logistica, Decision Tree, Random Forest si Kmeans, dar si o retea neuronala implementata cu Keras. De asemenea, se va urmari acuratetea, precizia si scorul F1 a acestor modele pentru a compara performanta."
      ],
      "metadata": {
        "id": "CMFC7uA4HLXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setul de date poate fi gasit: https://www.kaggle.com/datasets/dissfya/atp-tennis-2000-2023daily-pull/data \\\\\n",
        "Sau in arhiva incarcata"
      ],
      "metadata": {
        "id": "ixyC8ViqHOgE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tu0yXMr4j7h",
        "outputId": "e3673c06-193f-44df-b2fb-193b28fa012e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/atp-tennis-2000-2023daily-pull\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "#Descarcam setul de date\n",
        "path = kagglehub.dataset_download(\"dissfya/atp-tennis-2000-2023daily-pull\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpXbvgXFoGae",
        "outputId": "a0f54b3d-dd0f-4a09-d4f7-0777ed8bab14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['atp_tennis.csv']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#Verific locul unde a fost salvat setul de date\n",
        "print(os.listdir(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKExzpXGrSWB",
        "outputId": "da2f1e68-d9ba-4568-bf89-3c3307726da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "42 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP9YWQcsbEM5"
      },
      "outputs": [],
      "source": [
        "#Importuri necesare pentru rularea proiectului\n",
        "\n",
        "import findspark\n",
        "import pyspark\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.functions import lower, trim\n",
        "from pyspark.sql.functions import array, sort_array, col, concat_ws\n",
        "from pyspark.sql.functions import greatest, max\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression, NaiveBayes\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import when\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
        "import pandas as pd\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se initiaza o sesiune Spark si se incarca fisierul CSV cu datele."
      ],
      "metadata": {
        "id": "2dlgzITNIF3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnPUHC9SroBf"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ATP Tennis Project\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BplqvfCrrvJl",
        "outputId": "3fb20119-e35b-444e-cc2d-67cb07da620f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Tournament: string (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Series: string (nullable = true)\n",
            " |-- Court: string (nullable = true)\n",
            " |-- Surface: string (nullable = true)\n",
            " |-- Round: string (nullable = true)\n",
            " |-- Best of: integer (nullable = true)\n",
            " |-- Player_1: string (nullable = true)\n",
            " |-- Player_2: string (nullable = true)\n",
            " |-- Winner: string (nullable = true)\n",
            " |-- Rank_1: integer (nullable = true)\n",
            " |-- Rank_2: integer (nullable = true)\n",
            " |-- Pts_1: integer (nullable = true)\n",
            " |-- Pts_2: integer (nullable = true)\n",
            " |-- Odd_1: double (nullable = true)\n",
            " |-- Odd_2: double (nullable = true)\n",
            " |-- Score: string (nullable = true)\n",
            "\n",
            "+--------------------+----------+-------------+-------+-------+---------+-------+--------------+-------------+-----------+------+------+-----+-----+-----+-----+-----------+\n",
            "|          Tournament|      Date|       Series|  Court|Surface|    Round|Best of|      Player_1|     Player_2|     Winner|Rank_1|Rank_2|Pts_1|Pts_2|Odd_1|Odd_2|      Score|\n",
            "+--------------------+----------+-------------+-------+-------+---------+-------+--------------+-------------+-----------+------+------+-----+-----+-----+-----+-----------+\n",
            "|Australian Hardco...|2000-01-03|International|Outdoor|   Hard|1st Round|      3|    Dosedel S.|  Ljubicic I.| Dosedel S.|    63|    77|   -1|   -1| -1.0| -1.0|    6-4 6-2|\n",
            "|Australian Hardco...|2000-01-03|International|Outdoor|   Hard|1st Round|      3|    Clement A.|   Enqvist T.| Enqvist T.|    56|     5|   -1|   -1| -1.0| -1.0|    3-6 3-6|\n",
            "|Australian Hardco...|2000-01-03|International|Outdoor|   Hard|1st Round|      3|     Escude N.|Baccanello P.|  Escude N.|    40|   655|   -1|   -1| -1.0| -1.0|6-7 7-5 6-3|\n",
            "|Australian Hardco...|2000-01-03|International|Outdoor|   Hard|1st Round|      3|Knippschild J.|   Federer R.| Federer R.|    87|    65|   -1|   -1| -1.0| -1.0|    1-6 4-6|\n",
            "|Australian Hardco...|2000-01-03|International|Outdoor|   Hard|1st Round|      3|   Fromberg R.|Woodbridge T.|Fromberg R.|    81|   198|   -1|   -1| -1.0| -1.0|7-6 5-7 6-4|\n",
            "+--------------------+----------+-------------+-------+-------+---------+-------+--------------+-------------+-----------+------+------+-----+-----+-----+-----+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "csv_path = os.path.join(path, \"atp_tennis.csv\")\n",
        "\n",
        "# Se incarca fisierul CSV în Spark DataFrame\n",
        "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(csv_path)\n",
        "\n",
        "# Se afiseaza schema si primele 5 randuri\n",
        "df.printSchema()\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_xNnbUO9JoS",
        "outputId": "cdfed576-4010-4d5c-e191-8154d2aa03c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|Round        |\n",
            "+-------------+\n",
            "|1st Round    |\n",
            "|Quarterfinals|\n",
            "|Semifinals   |\n",
            "|The Final    |\n",
            "|4th Round    |\n",
            "|Round Robin  |\n",
            "|2nd Round    |\n",
            "|3rd Round    |\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza toate valorile feature-ului Round\n",
        "df.select(\"Round\").distinct().show(100, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procesarea, pregatirea, curatarea datelor"
      ],
      "metadata": {
        "id": "RwotPsvuIaxF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKjR80rg1LMF"
      },
      "outputs": [],
      "source": [
        "#Se sterg duplicatele\n",
        "df = df.dropDuplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRGtrRgt55P8"
      },
      "outputs": [],
      "source": [
        "#Textul din coloanele Tournament, Series, Court, Surface, Round, Player_1, Player_2, Winner este transformat in litere mici si sunt eliminate spatiile de la inceput si final\n",
        "\n",
        "for colname in [\"Tournament\", \"Series\", \"Court\", \"Surface\", \"Round\", \"Player_1\", \"Player_2\", \"Winner\"]:\n",
        "    df = df.withColumn(colname, lower(trim(col(colname))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agregari si Grupari de Date"
      ],
      "metadata": {
        "id": "CR4f-AChImx5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI0uoq0kQ43O",
        "outputId": "6b74e4c8-f685-4447-d733-7a1dc4a8a5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|Surface|count|\n",
            "+-------+-----+\n",
            "|   hard|35345|\n",
            "|   clay|21283|\n",
            "|  grass| 7157|\n",
            "| carpet| 1632|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza numarul de meciuri jucate per suprafata\n",
        "df.groupBy(\"Surface\").count().orderBy(\"count\", ascending=False).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFAgnapcUsRU",
        "outputId": "53f37c19-2b48-4ea3-e22e-e0924b4a04d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|Surface|num_matches|\n",
            "+-------+-----------+\n",
            "|   hard|      35345|\n",
            "|   clay|      21283|\n",
            "|  grass|       7157|\n",
            "| carpet|       1632|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza numarul de meciuri jucate per suprafata folosind Spark SQL\n",
        "\n",
        "df.createOrReplaceTempView(\"matches\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "  SELECT Surface, COUNT(*) as num_matches\n",
        "  FROM matches\n",
        "  GROUP BY Surface\n",
        "  ORDER BY num_matches DESC\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg-g5nv_R2au",
        "outputId": "856448be-105f-4d15-b608-547a18ae1a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "|     Winner|count|\n",
            "+-----------+-----+\n",
            "| federer r.| 1157|\n",
            "|djokovic n.| 1047|\n",
            "|   nadal r.| 1009|\n",
            "|  ferrer d.|  678|\n",
            "|  murray a.|  675|\n",
            "| gasquet r.|  577|\n",
            "| berdych t.|  576|\n",
            "| roddick a.|  564|\n",
            "| monfils g.|  553|\n",
            "|wawrinka s.|  535|\n",
            "+-----------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza numarul de meciuri castigate per jucator\n",
        "df.groupBy(\"Winner\").count().orderBy(\"count\", ascending=False).show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEmAkEAqrvzr",
        "outputId": "d4d442d4-2a29-47c8-da48-ba364c8fc2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "|      Winner|num_matches|\n",
            "+------------+-----------+\n",
            "|  federer r.|       1157|\n",
            "| djokovic n.|       1047|\n",
            "|    nadal r.|       1009|\n",
            "|   ferrer d.|        678|\n",
            "|   murray a.|        675|\n",
            "|  gasquet r.|        577|\n",
            "|  berdych t.|        576|\n",
            "|  roddick a.|        564|\n",
            "|  monfils g.|        553|\n",
            "| wawrinka s.|        535|\n",
            "|    cilic m.|        533|\n",
            "| verdasco f.|        526|\n",
            "|  robredo t.|        504|\n",
            "|   hewitt l.|        494|\n",
            "|    simon g.|        479|\n",
            "|    lopez f.|        472|\n",
            "|    isner j.|        466|\n",
            "|davydenko n.|        461|\n",
            "|  youzhny m.|        459|\n",
            "|   zverev a.|        448|\n",
            "+------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza numarul de meciuri castigate per jucator folosind Spark SQL\n",
        "df.createOrReplaceTempView(\"matches\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "  SELECT Winner, COUNT(*) as num_matches\n",
        "  FROM matches\n",
        "  GROUP BY Winner\n",
        "  ORDER BY num_matches DESC\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq6SNM8vTEQ3",
        "outputId": "69c1d733-380f-4546-95ee-128b9ba887ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----------+-----+\n",
            "|         Tournament|     Winner|count|\n",
            "+-------------------+-----------+-----+\n",
            "|        french open|   nadal r.|  109|\n",
            "|          wimbledon| federer r.|  103|\n",
            "|    australian open| federer r.|  100|\n",
            "|        french open|djokovic n.|   97|\n",
            "|    australian open|djokovic n.|   97|\n",
            "|          wimbledon|djokovic n.|   96|\n",
            "|            us open| federer r.|   87|\n",
            "|            us open|djokovic n.|   84|\n",
            "|    australian open|   nadal r.|   74|\n",
            "|monte carlo masters|   nadal r.|   73|\n",
            "+-------------------+-----------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza jucatorul cu cele mai multe titluri castigate per turneu\n",
        "df.groupBy(\"Tournament\", \"Winner\").count().orderBy(\"count\", ascending=False).show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9NXM2lMsb5b",
        "outputId": "17f2b721-f8a2-41a0-9138-f3b24376328e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+-----------+\n",
            "|          Tournament|     Winner|num_matches|\n",
            "+--------------------+-----------+-----------+\n",
            "|         french open|   nadal r.|        109|\n",
            "|           wimbledon| federer r.|        103|\n",
            "|     australian open| federer r.|        100|\n",
            "|         french open|djokovic n.|         97|\n",
            "|     australian open|djokovic n.|         97|\n",
            "|           wimbledon|djokovic n.|         96|\n",
            "|             us open| federer r.|         87|\n",
            "|             us open|djokovic n.|         84|\n",
            "|     australian open|   nadal r.|         74|\n",
            "| monte carlo masters|   nadal r.|         73|\n",
            "|         french open| federer r.|         72|\n",
            "|internazionali bn...|djokovic n.|         66|\n",
            "|    gerry weber open| federer r.|         63|\n",
            "|             us open|   nadal r.|         63|\n",
            "|           wimbledon|  murray a.|         61|\n",
            "|         masters cup| federer r.|         59|\n",
            "|internazionali bn...|   nadal r.|         57|\n",
            "|           wimbledon|   nadal r.|         57|\n",
            "|       swiss indoors| federer r.|         53|\n",
            "|         masters cup|djokovic n.|         50|\n",
            "+--------------------+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza jucatorul cu cele mai multe titluri castigate per turneu folosind Spark SQL\n",
        "\n",
        "df.createOrReplaceTempView(\"matches\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "  SELECT Tournament, Winner, COUNT(*) as num_matches\n",
        "  FROM matches\n",
        "  GROUP BY Tournament, Winner\n",
        "  ORDER BY num_matches DESC\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2DqNaxHTXxQ",
        "outputId": "e3762115-e306-44b7-c7d8-e9a27074ad1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+-----+\n",
            "|pair                        |count|\n",
            "+----------------------------+-----+\n",
            "|djokovic n. vs nadal r.     |54   |\n",
            "|djokovic n. vs federer r.   |48   |\n",
            "|federer r. vs nadal r.      |40   |\n",
            "|djokovic n. vs murray a.    |34   |\n",
            "|ferrer d. vs nadal r.       |30   |\n",
            "|federer r. vs wawrinka s.   |26   |\n",
            "|federer r. vs murray a.     |24   |\n",
            "|federer r. vs roddick a.    |24   |\n",
            "|del potro j.m. vs federer r.|24   |\n",
            "|djokovic n. vs wawrinka s.  |23   |\n",
            "+----------------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza perechile de jucatori care s-au intalnit de cele mai multe ori\n",
        "df_pairs = df.withColumn(\"pair\", concat_ws(\" vs \", sort_array(array(\"Player_1\", \"Player_2\"))))\n",
        "df_pairs.groupBy(\"pair\").count().orderBy(\"count\", ascending=False).show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s7ixy8lXMP1",
        "outputId": "475a56b4-4bf8-4fd7-9d19-77dd22a51f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+-----------+\n",
            "|pair                        |num_matches|\n",
            "+----------------------------+-----------+\n",
            "|djokovic n. vs nadal r.     |54         |\n",
            "|djokovic n. vs federer r.   |48         |\n",
            "|federer r. vs nadal r.      |40         |\n",
            "|djokovic n. vs murray a.    |34         |\n",
            "|ferrer d. vs nadal r.       |30         |\n",
            "|federer r. vs wawrinka s.   |26         |\n",
            "|federer r. vs murray a.     |24         |\n",
            "|federer r. vs roddick a.    |24         |\n",
            "|del potro j.m. vs federer r.|24         |\n",
            "|federer r. vs hewitt l.     |23         |\n",
            "+----------------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza perechile de jucatori care s-au intalnit de cele mai multe ori folosind Spark SQL\n",
        "\n",
        "df = df.withColumn(\"pair\", concat_ws(\" vs \", sort_array(array(\"Player_1\", \"Player_2\"))))\n",
        "\n",
        "df.createOrReplaceTempView(\"matches\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT pair, COUNT(*) AS num_matches\n",
        "    FROM matches\n",
        "    GROUP BY pair\n",
        "    ORDER BY num_matches DESC\n",
        "    LIMIT 10\n",
        "\"\"\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqx9UAx0ZpOu",
        "outputId": "f3fb5285-67d5-4382-dfd6-79da0232a002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|unique_players|\n",
            "+--------------+\n",
            "|          1670|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza numarul total de jucători unici in Player_1 si Player_2\n",
        "df.select(\"Player_1\").union(df.select(\"Player_2\")).agg(countDistinct(\"Player_1\").alias(\"unique_players\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iZrVH5DsweH",
        "outputId": "367a6526-de9c-47e8-e064-2568a3fde7a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|unique_players|\n",
            "+--------------+\n",
            "|          1670|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza numarul total de jucători unici in Player_1 si Player_2 folosind Spark SQL\n",
        "\n",
        "df.createOrReplaceTempView(\"matches\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT COUNT(DISTINCT Player) AS unique_players\n",
        "    FROM (\n",
        "      SELECT Player_1 AS Player FROM matches\n",
        "      UNION\n",
        "      SELECT Player_2 AS Player FROM matches\n",
        "    )\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYCKEZYaa2Q7",
        "outputId": "2bbd112d-c6ee-46f5-bc9b-4d45f921e4c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|      avg_pts_diff|\n",
            "+------------------+\n",
            "|1022.3205894492257|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza diferenta medie intre punctajul celor doi jucatori\n",
        "df.withColumn(\"pts_diff\", abs(df[\"Pts_1\"] - df[\"Pts_2\"])) \\\n",
        "  .agg(avg(\"pts_diff\").alias(\"avg_pts_diff\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ErK-tfNtwu2",
        "outputId": "0273edbd-0fae-413e-c371-c898d2f9d6a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|      avg_pts_diff|\n",
            "+------------------+\n",
            "|1022.3205894492257|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza diferenta medie intre punctajul celor doi jucatori folosind Spark SQL\n",
        "\n",
        "df.createOrReplaceTempView(\"matches\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT AVG(ABS(Pts_1 - Pts_2)) AS avg_pts_diff\n",
        "    FROM matches\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M78JSrbWa5o2",
        "outputId": "e7fc052e-4268-4c6a-f8cb-fd4a66050476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numărul maxim de puncte ATP într-un meci (player 1 sau 2): 16950\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza numarul maxim de puncte ATP al unui jucator intr-un meci\n",
        "\n",
        "df_with_max_pts = df.withColumn(\"max_pts_in_match\", greatest(\"Pts_1\", \"Pts_2\"))\n",
        "max_pts = df_with_max_pts.agg(max(\"max_pts_in_match\").alias(\"max_points\")).collect()[0][\"max_points\"]\n",
        "print(f\"Numărul maxim de puncte ATP într-un meci (player 1 sau 2): {max_pts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln87UdNbuWKn",
        "outputId": "b553e57a-934d-4b87-a167-46bfce177470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|max_pts|\n",
            "+-------+\n",
            "|  16950|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza numarul maxim de puncte ATP al unui jucator intr-un meci folosind Spark SQL\n",
        "\n",
        "df.createOrReplaceTempView(\"matches\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT MAX(GREATEST(Pts_1, Pts_2)) as max_pts\n",
        "    FROM matches\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformarea datelor"
      ],
      "metadata": {
        "id": "c_wkga8bIvrn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApMEA4nf3XEW"
      },
      "outputs": [],
      "source": [
        "#Transformarea datelor\n",
        "\n",
        "# Valorile din Round sunt transformate in numere intregi\n",
        "\n",
        "df = df.withColumn(\"Round_num\",\n",
        "    when(df[\"Round\"] == \"1st round\", 1)\n",
        "    .when(df[\"Round\"] == \"2nd round\", 2)\n",
        "    .when(df[\"Round\"] == \"3rd round\", 3)\n",
        "    .when(df[\"Round\"] == \"4th round\", 4)\n",
        "    .when(df[\"Round\"] == \"quarterfinals\", 5)\n",
        "    .when(df[\"Round\"] == \"semifinals\", 6)\n",
        "    .when(df[\"Round\"] == \"the final\", 7)\n",
        "    .when(df[\"Round\"] == \"round robin\", 8)\n",
        "    .otherwise(None)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxLTmZIC-iXY"
      },
      "outputs": [],
      "source": [
        "# Coloane categorice\n",
        "categorical_cols = [\"Surface\", \"Series\", \"Court\"]\n",
        "\n",
        "# Coloane numerice\n",
        "numerical_cols = [\"Rank_1\", \"Rank_2\", \"Best of\", \"Round_num\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn6A4J4_-nzq"
      },
      "outputs": [],
      "source": [
        "#Coloanele cateorice sunt transformate in numere cu ajutorul StringIndexer\n",
        "#Noile coloane numerice sunt adunate cu cele deja existenta intr-o lista\n",
        "#VectorAssembler combina toate aceste coloane intr-un singur vector numit features\n",
        "\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_idx\") for col in categorical_cols]\n",
        "feature_cols = [col + \"_idx\" for col in categorical_cols] + numerical_cols\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nUSpMTM-uts"
      },
      "outputs": [],
      "source": [
        "#Se creeaza o coloana noua in df. In aceasta, meciurile vor fi etichetate cu 1 daca Player_1 a castigat si cu 0 daca nu\n",
        "df_1 = df.withColumn(\"label\", when(df[\"Winner\"] == df[\"Player_1\"], 1).otherwise(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7L147UI3n4L"
      },
      "outputs": [],
      "source": [
        "#Se construieste pipeline-ul si se antreneaza pe DataFrame-ul df_1\n",
        "pipeline = Pipeline(stages=indexers + [assembler])\n",
        "df_1 = pipeline.fit(df_1).transform(df_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnygAuun4Yfe"
      },
      "outputs": [],
      "source": [
        "#Setul de date este impartit in train_data, care este folosit pentru antrenarea modelului si test_data, care este folosit pentru evaluarea modelului\n",
        "train_data, test_data = df_1.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metode ML"
      ],
      "metadata": {
        "id": "l_Ik5FOOWw8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresie Logistica / Logistic Regression"
      ],
      "metadata": {
        "id": "t9CK5c3PI4oP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresia Logistica este folosita pentru prezicerea probabilitatii ca jucatorul 1 sa fie castigatorul meciului, pe baza unor factori precum clasamentele jucatorilor, tipul terenului, runda si alte caracteristici ale meciului."
      ],
      "metadata": {
        "id": "KaJugyikJxFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Am ales regresia logistica pentru ca este un alogirtm simplu si eficient pentru problemele de clasificare binara."
      ],
      "metadata": {
        "id": "6CaaJGsHKLVL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx8xGnFJ4fk0"
      },
      "outputs": [],
      "source": [
        "#Regresie Logistica\n",
        "#Modelul este creat, antrenat si folosit pentru a face predictii pe datele de test\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_data)\n",
        "lr_preds = lr_model.transform(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "Q0pMUBUgI9xQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fel ca pentru regresia logistica, Random Forest este folosit pentru clasificarea rezultatului unui meci ca victorie sau infrangere pentru jucatorul 1."
      ],
      "metadata": {
        "id": "7ggGZZJaLFer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Am ales Random Forest datorita capacitatii sale de a gestiona eficient date cu multe trasaturi."
      ],
      "metadata": {
        "id": "0nKHgW2mLOoR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93CyXFAlBxUj"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "#Modelul este creat, antrenat si folosit pentru a face predictii pe datele de test\n",
        "\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
        "rf_model = rf.fit(train_data)\n",
        "rf_preds = rf_model.transform(test_data)\n",
        "rf_preds = rf_preds.withColumn(\"prediction\", col(\"prediction\").cast(\"double\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {
        "id": "kKO1ruHnI_sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fel ca la modelele anterioare, se doreste prezicerea rezultatului unui meci ATP."
      ],
      "metadata": {
        "id": "8ZFkScYBLkJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Am ales Decision Tree deoarece antrenarea este rapida si scalabila chiar si pe volume mari de date."
      ],
      "metadata": {
        "id": "nlqDvQM-LvOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiA1G0W6M_2Y"
      },
      "outputs": [],
      "source": [
        "#Decision Tree\n",
        "#Modelul este creat, antrenat si folosit pentru a face predictii pe datele de test\n",
        "\n",
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=5)\n",
        "dt_model = dt.fit(train_data)\n",
        "dt_preds = dt_model.transform(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compararea acuratetii, preciziei si scorului F1 intre Regresia Logistica, Decision Tree si Random Forest"
      ],
      "metadata": {
        "id": "UTTcE6PtJCbi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Beq6GY9P5EOZ",
        "outputId": "fb38dde7-6521-4e23-e292-8b2a3d8a3647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acuratete Regresie Logistica: 0.6554550375009666\n",
            "Acuratete Random Forest: 0.6548364648573417\n",
            "Acuratete Decision Tree: 0.6489600247429057\n",
            "F1 Score Regresie Logistica: 0.6554529487544276\n",
            "F1 Score Random Forest: 0.654692005529655\n",
            "F1 Score Decision Tree: 0.6476521184006685\n",
            "Precision Regresie Logistica: 0.6518734643734644\n",
            "Precision Random Forest: 0.6588709677419354\n",
            "Precision Decision Tree: 0.6667840789010215\n"
          ]
        }
      ],
      "source": [
        "#Sunt afisate acuratetea, precizia si scorul F1 pentru modele\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "print(\"Acuratete Regresie Logistica:\", evaluator.evaluate(lr_preds))\n",
        "print(\"Acuratete Random Forest:\", evaluator.evaluate(rf_preds))\n",
        "print(f\"Acuratete Decision Tree:\", evaluator.evaluate(dt_preds))\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "print(\"F1 Score Regresie Logistica:\", evaluator.evaluate(lr_preds))\n",
        "print(\"F1 Score Random Forest:\", evaluator.evaluate(rf_preds))\n",
        "print(\"F1 Score Decision Tree:\", evaluator.evaluate(dt_preds))\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "print(\"Precision Regresie Logistica:\", evaluator.evaluate(lr_preds))\n",
        "print(\"Precision Random Forest:\", evaluator.evaluate(rf_preds))\n",
        "print(\"Precision Decision Tree:\", evaluator.evaluate(dt_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KMeans"
      ],
      "metadata": {
        "id": "jpBdqCndJMEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KMeans a fost aplicat pentru a descoperi structuri si tipare ascunse in date. Algoritmul este eficient in gruparea jucatorilor sau meciurilor pe baza caracteristicilor si ofera o perspectiva utila asupra datelor."
      ],
      "metadata": {
        "id": "yPyhQhqgVts6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Am ales KMean pentru ca este un algoritm eficient de clustering, util in explorarea tiparelor din date."
      ],
      "metadata": {
        "id": "CTEFMr9aWAM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MamYWKa4CV0o",
        "outputId": "80dc921c-3132-42e8-c22b-85f55972db27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+--------------------+----------+\n",
            "|      Player_1|    Player_2|            features|prediction|\n",
            "+--------------+------------+--------------------+----------+\n",
            "|    kroslak j.|  jonsson f.|[0.0,2.0,0.0,103....|         4|\n",
            "| gustafsson m.|johansson t.|[0.0,2.0,0.0,60.0...|         1|\n",
            "|     dupuis a.|rodriguez m.|[0.0,1.0,0.0,98.0...|         4|\n",
            "|       haas t.| saulnier c.|[0.0,1.0,0.0,12.0...|         4|\n",
            "|    sluiter r.| gaudenzi a.|[0.0,1.0,0.0,166....|         0|\n",
            "|    ullyett k.|   tabara m.|[0.0,1.0,0.0,182....|         0|\n",
            "|    russell m.|  armando h.|[1.0,2.0,0.0,165....|         4|\n",
            "|      pavel a.| medvedev a.|[1.0,2.0,0.0,43.0...|         1|\n",
            "|   medvedev a.|   norman m.|[1.0,1.0,0.0,20.0...|         1|\n",
            "|di pasquale a.|  sluiter r.|[1.0,2.0,0.0,53.0...|         4|\n",
            "+--------------+------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#KMeans\n",
        "\n",
        "#Coloanele cateorice sunt transformate in numere cu ajutorul StringIndexer\n",
        "categorical_cols = [\"Surface\", \"Series\", \"Court\"]\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_idx\") for col in categorical_cols]\n",
        "\n",
        "#Coloane numerice\n",
        "numerical_cols = [\"Rank_1\", \"Rank_2\", \"Best of\", \"Round_num\"]\n",
        "\n",
        "#Se construieste pipeline-ul\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "df_2 = pipeline.fit(df).transform(df)\n",
        "\n",
        "#Coloanele cateorice sunt transformate in numere cu ajutorul StringIndexer\n",
        "#Noile coloane numerice sunt adunate cu cele deja existenta intr-o lista\n",
        "#VectorAssembler combina toate aceste coloane intr-un singur vector numit features\n",
        "\n",
        "feature_cols = [col + \"_idx\" for col in categorical_cols] + numerical_cols\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "df_2_features = assembler.transform(df_2)\n",
        "\n",
        "#Se aplica KMeans cu k=5\n",
        "kmeans = KMeans(featuresCol=\"features\", k=5)\n",
        "k_model = kmeans.fit(df_2_features)\n",
        "\n",
        "#Se afiseaza primele 10 randuri cu jucatori\n",
        "clusters = k_model.transform(df_2_features)\n",
        "clusters.select(\"Player_1\", \"Player_2\", \"features\", \"prediction\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3-TdQZNLVsh",
        "outputId": "6225531e-58ee-40cd-d785-1d0cde608325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|         0| 5940|\n",
            "|         1|49136|\n",
            "|         2|  627|\n",
            "|         3|  797|\n",
            "|         4| 8917|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza distributia datelor in cele 5 clustere\n",
        "clusters.groupBy(\"prediction\").count().orderBy(\"prediction\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B1_vr5_MRYV",
        "outputId": "a9bedc17-91cb-42a3-e79d-917490976377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0 center: [6.84361792e-01 1.63516484e+00 1.66187658e-01 2.28597633e+02\n",
            " 6.88696534e+01 3.38038884e+00 1.66745562e+00]\n",
            "Cluster 1 center: [ 0.60002445  2.22698836  0.18272777 50.08499582 46.05345098  3.38029059\n",
            "  2.49401911]\n",
            "Cluster 2 center: [6.76800e-01 1.78880e+00 1.40800e-01 7.83120e+02 8.85248e+01 3.23040e+00\n",
            " 1.46240e+00]\n",
            "Cluster 3 center: [6.700000e-01 1.608750e+00 1.662500e-01 8.847625e+01 7.033150e+02\n",
            " 3.215000e+00 1.437500e+00]\n",
            "Cluster 4 center: [6.70924034e-01 1.73000888e+00 1.64704576e-01 6.55980675e+01\n",
            " 1.83620280e+02 3.38427366e+00 1.70457574e+00]\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza centrele clusterelor\n",
        "centers = k_model.clusterCenters()\n",
        "for i, center in enumerate(centers):\n",
        "    print(f\"Cluster {i} center: {center}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V8kbS_6MZKA",
        "outputId": "496a6fb3-20eb-41c7-ff89-2b068757ca98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+-----+\n",
            "|prediction|Surface|count|\n",
            "+----------+-------+-----+\n",
            "|         0|   hard| 2938|\n",
            "|         0| carpet|  113|\n",
            "|         0|   clay| 2053|\n",
            "|         0|  grass|  836|\n",
            "|         1|   hard|27229|\n",
            "|         1|   clay|15651|\n",
            "|         1| carpet| 1315|\n",
            "|         1|  grass| 4941|\n",
            "|         2|  grass|   90|\n",
            "|         2|   hard|  319|\n",
            "|         2| carpet|   13|\n",
            "|         2|   clay|  205|\n",
            "|         3|  grass|   96|\n",
            "|         3|   hard|  393|\n",
            "|         3| carpet|   18|\n",
            "|         3|   clay|  290|\n",
            "|         4|  grass| 1194|\n",
            "|         4|   hard| 4466|\n",
            "|         4| carpet|  173|\n",
            "|         4|   clay| 3084|\n",
            "+----------+-------+-----+\n",
            "\n",
            "+----------+------------------+-----+\n",
            "|prediction|            Series|count|\n",
            "+----------+------------------+-----+\n",
            "|         0|           masters|  140|\n",
            "|         0|        grand slam| 1126|\n",
            "|         0|            atp500|  386|\n",
            "|         0|            atp250| 2093|\n",
            "|         0|     international| 1426|\n",
            "|         0|international gold|  394|\n",
            "|         0|      masters 1000|  375|\n",
            "|         1|      masters 1000| 7899|\n",
            "|         1|            atp250|11636|\n",
            "|         1|     international| 7773|\n",
            "|         1|       masters cup|  372|\n",
            "|         1|international gold| 2481|\n",
            "|         1|            atp500| 5133|\n",
            "|         1|           masters| 4574|\n",
            "|         1|        grand slam| 9268|\n",
            "|         2|international gold|   48|\n",
            "|         2|           masters|   20|\n",
            "|         2|            atp250|  225|\n",
            "|         2|            atp500|   52|\n",
            "|         2|        grand slam|   72|\n",
            "+----------+------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----------+---------+------------------+------------------+\n",
            "|prediction|Round_num|       avg(Rank_1)|       avg(Rank_2)|\n",
            "+----------+---------+------------------+------------------+\n",
            "|         0|        7|202.45652173913044|46.391304347826086|\n",
            "|         0|        5| 222.5017182130584|  62.4639175257732|\n",
            "|         0|        1|231.68139963167587| 77.96158905551171|\n",
            "|         0|        8|196.85714285714286| 74.57142857142857|\n",
            "|         0|        6|214.82456140350877|  59.8859649122807|\n",
            "|         0|        2|224.33421575115818|  51.7180675049636|\n",
            "|         0|        3|210.83892617449663|40.604026845637584|\n",
            "|         0|        4|182.92857142857142|22.428571428571427|\n",
            "|         1|        7|30.424181696726787|28.093520374081496|\n",
            "|         1|        2|51.097070243558065| 46.91973173314508|\n",
            "|         1|        1|61.107109927261554| 56.26047536113103|\n",
            "|         1|        3| 34.16081593927894| 31.90962998102467|\n",
            "|         1|        4| 25.05134899912968|24.469973890339425|\n",
            "|         1|        8|17.796246648793566| 18.06970509383378|\n",
            "|         1|        5|  40.8310861423221| 37.63314606741573|\n",
            "|         1|        6|34.988169798190675|32.374043145441895|\n",
            "|         2|        2|            741.41|             50.97|\n",
            "|         2|        3|           713.375|            41.375|\n",
            "|         2|        5| 942.6315789473684|  65.6842105263158|\n",
            "|         2|        1|  787.098532494759| 99.62054507337527|\n",
            "+----------+---------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza cate meciuri pe fiecare tip de suprafata exista in fiecare cluster\n",
        "clusters.groupBy(\"prediction\", \"Surface\").count().orderBy(\"prediction\").show()\n",
        "\n",
        "#Se afiseaza cate meciuri din fiecare tip de turneu exista in fiecare cluster\n",
        "clusters.groupBy(\"prediction\", \"Series\").count().orderBy(\"prediction\").show()\n",
        "\n",
        "#Se afiseaza media clasamentului jucatorilor pentru fiecare cluster si runda a turneului\n",
        "clusters.groupBy(\"prediction\", \"Round_num\").avg(\"Rank_1\", \"Rank_2\").orderBy(\"prediction\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MBHxvo6YZg_",
        "outputId": "5103c98e-fde7-4f52-e08d-b5817b9fcfdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scorul Silhouette: 0.6921\n"
          ]
        }
      ],
      "source": [
        "#Se evalueaza clusterele\n",
        "evaluator = ClusteringEvaluator(predictionCol=\"prediction\", featuresCol=\"features\", metricName=\"silhouette\")\n",
        "silhouette = evaluator.evaluate(clusters)\n",
        "print(f\"Scorul Silhouette: {silhouette:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM7u0UfnMjgh",
        "outputId": "e5c78683-7719-431d-9f21-bf4e87fcc0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+-------+---------+------+------+----------+\n",
            "|      Player_1|     Player_2|Surface|Round_num|Rank_1|Rank_2|prediction|\n",
            "+--------------+-------------+-------+---------+------+------+----------+\n",
            "|    kroslak j.|   jonsson f.|   hard|        1|   103|   127|         4|\n",
            "| gustafsson m.| johansson t.|   hard|        2|    60|    43|         1|\n",
            "|     dupuis a.| rodriguez m.|   hard|        1|    98|   119|         4|\n",
            "|       haas t.|  saulnier c.|   hard|        1|    12|   171|         4|\n",
            "|    sluiter r.|  gaudenzi a.|   hard|        1|   166|    88|         0|\n",
            "|    ullyett k.|    tabara m.|   hard|        1|   182|   122|         0|\n",
            "|    russell m.|   armando h.|   clay|        1|   165|   239|         4|\n",
            "|      pavel a.|  medvedev a.|   clay|        5|    43|    21|         1|\n",
            "|   medvedev a.|    norman m.|   clay|        4|    20|     3|         1|\n",
            "|di pasquale a.|   sluiter r.|   clay|        2|    53|   142|         4|\n",
            "| goellner m.k.| squillari f.|   clay|        2|   330|    20|         0|\n",
            "|     kiefer n.|    martin t.|   hard|        1|    12|    30|         1|\n",
            "|      pozzi g.|el aynaoui y.|   hard|        2|    50|    22|         1|\n",
            "|   krajicek r.|    norman m.|   hard|        6|    25|     3|         1|\n",
            "|   krajicek r.|   sampras p.|   hard|        5|    23|     4|         1|\n",
            "|      bastl g.|    dupuis a.|   hard|        2|    84|   148|         4|\n",
            "|vinciguerra a.|     novak j.|   hard|        1|    52|    40|         1|\n",
            "|  voltchkov v.|  zabaleta m.|   hard|        2|    56|    63|         1|\n",
            "|  voltchkov v.|  ljubicic i.|   hard|        5|    52|    89|         1|\n",
            "|       haas t.|     massu n.|   hard|        7|    23|    87|         1|\n",
            "+--------------+-------------+-------+---------+------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza predictiile pentru clustere\n",
        "clusters.select(\"Player_1\", \"Player_2\", \"Surface\", \"Round_num\", \"Rank_1\", \"Rank_2\", \"prediction\").show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O10Vcy9E0MuJ"
      },
      "outputs": [],
      "source": [
        "#Se creeaza o coloana noua in df. In aceasta, meciurile vor fi etichetate cu 1 daca Player_1 a castigat si cu 0 daca nu\n",
        "df_3 = df.withColumn(\"label\", when(df[\"Winner\"] == df[\"Player_1\"], 1).otherwise(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizarea unei functii definite de utilizator"
      ],
      "metadata": {
        "id": "g4fRDfpEXDfv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMKZq6ILMuuK"
      },
      "outputs": [],
      "source": [
        "#Se defineste o functie UDF in care se calculeaza diferenta absoluta dintre pozitiile in clasament a jucatorilor\n",
        "@pandas_udf(\"int\")\n",
        "def rank_diff(rank1: pd.Series, rank2: pd.Series) -> pd.Series:\n",
        "    return (rank1 - rank2).abs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAiMCL-NM19u"
      },
      "outputs": [],
      "source": [
        "#Se creeaza o coloana noua in df. Aceasta va contine diferenta dintre pozitiile in clasament a jucatorilor\n",
        "df_3 = df_3.withColumn(\"ranking_diff\", rank_diff(df[\"Rank_1\"], df[\"Rank_2\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnsrq4VwNSCg"
      },
      "outputs": [],
      "source": [
        "#Se construieste pipeline-ul si se antreneaza pe DataFrame-ul df_3\n",
        "pipeline = Pipeline(stages=indexers + [assembler])\n",
        "df_3 = pipeline.fit(df_3).transform(df_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mFg7Gu2NaJM"
      },
      "outputs": [],
      "source": [
        "#Setul de date este impartit in train_data, care este folosit pentru antrenarea modelului si test_data, care este folosit pentru evaluarea modelului\n",
        "train_data, test_data = df_3.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizarea hiperparametrilor"
      ],
      "metadata": {
        "id": "Ngb2xaFGXJhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Am antrenat un model de regresie logistică si am testat mai multe combinatii de hiperparametri (cu CrossValidator) ca sa gasesc varianta care da cele mai bune rezultate. Apoi am folosit acel model optimizat pe datele de test."
      ],
      "metadata": {
        "id": "YcbM_pIWXMyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kmD4MvT6KXx",
        "outputId": "91a78df2-e936-44ea-b6f2-af37bedc0b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cel mai bun regParam: 0.01\n",
            "Cel mai bun elasticNetParam: 0.5\n",
            "Cel mai bun maxIter: 100\n"
          ]
        }
      ],
      "source": [
        "#Regresie Logistica optimizata\n",
        "\n",
        "#Va evalua modelele dupa metrica AUC\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "#Se initializeaza modelul\n",
        "lr_optimized = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "#Se construieste gridul de hiperparametri\n",
        "paramGrid_lr = ParamGridBuilder() \\\n",
        "    .addGrid(lr_optimized.regParam, [0.01, 0.1, 0.5]) \\\n",
        "    .addGrid(lr_optimized.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .addGrid(lr_optimized.maxIter, [50, 100]) \\\n",
        "    .build()\n",
        "\n",
        "#cv_lr va testa fiecare combinatie de hiperparametri\n",
        "cv_lr = CrossValidator(estimator=lr_optimized,\n",
        "                       estimatorParamMaps=paramGrid_lr,\n",
        "                       evaluator=evaluator,\n",
        "                       numFolds=5)\n",
        "\n",
        "#Se antreneaza modelul folosind cv_lr\n",
        "cv_model_lr = cv_lr.fit(train_data)\n",
        "\n",
        "#Se afiseaza cei mai buni hiperparametri gasiti\n",
        "print(\"Cel mai bun regParam:\", cv_model_lr.bestModel._java_obj.getRegParam())\n",
        "print(\"Cel mai bun elasticNetParam:\", cv_model_lr.bestModel._java_obj.getElasticNetParam())\n",
        "print(\"Cel mai bun maxIter:\", cv_model_lr.bestModel._java_obj.getMaxIter())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNlLNANDFusF"
      },
      "outputs": [],
      "source": [
        "#Se aplica cel mai bun model logistic antrenat\n",
        "lr_optimized_pred = cv_model_lr.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RvW24In84nu",
        "outputId": "ca1a86c2-06ef-4892-9e9c-b22406fbf1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|            features|label|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|[0.0,2.0,0.0,79.0...|    1|[-0.0648398370869...|[0.48379571750691...|       1.0|\n",
            "|[0.0,2.0,0.0,112....|    1|[-0.5306186781115...|[0.37037260274845...|       1.0|\n",
            "|[0.0,2.0,0.0,67.0...|    0|[-0.2999936512268...|[0.42555903519944...|       1.0|\n",
            "|[0.0,2.0,0.0,79.0...|    0|[0.06588896552386...|[0.51646628464529...|       0.0|\n",
            "|[0.0,2.0,0.0,88.0...|    0|[0.28624959623819...|[0.57107772508877...|       0.0|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Se afiseaza un esantion de predictii\n",
        "lr_optimized_pred.select(\"features\", \"label\", \"rawPrediction\", \"probability\", \"prediction\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e-HFbzyHPIV",
        "outputId": "7e6bfb2d-bcfc-4955-8b9b-de9e8c090215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Logistic Regression: 0.6552230727596072\n",
            "F1 Score Logistic Regression: 0.655221168123625\n",
            "Precision Logistic Regression: 0.6516664106896022\n"
          ]
        }
      ],
      "source": [
        "#Sunt afisate acuratetea, precizia si scorul F1 pentru model\n",
        "predictionAndLabels = lr_optimized_pred.select(\"prediction\", \"label\").rdd.map(tuple)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "print(\"Accuracy Logistic Regression:\", evaluator.evaluate(lr_optimized_pred))\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "print(\"F1 Score Logistic Regression:\", evaluator.evaluate(lr_optimized_pred))\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
        "print(\"Precision Logistic Regression:\", evaluator.evaluate(lr_optimized_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicarea unei metode DL - Neural Network"
      ],
      "metadata": {
        "id": "ygCmlXir1qYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Am folosit Neural Network pentru prezicerea castigatorului unui meci de tenis pe baza unor date istorice."
      ],
      "metadata": {
        "id": "Igo5cHEnXkFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Am ales neural network deoarece are performanta ridicata in clasificare."
      ],
      "metadata": {
        "id": "qxQPpey3XvZ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEByT0zSVvgT"
      },
      "outputs": [],
      "source": [
        "#Se creeaza o coloana noua in df. In aceasta, meciurile vor fi etichetate cu 1 daca Player_1 a castigat si cu 0 daca nu\n",
        "df_dl = df.withColumn(\"label\", when(df[\"Winner\"] == df[\"Player_1\"], 1).otherwise(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPGTseJCVyhA"
      },
      "outputs": [],
      "source": [
        "#Se construieste pipeline-ul si se antreneaza pe DataFrame-ul df_dl\n",
        "pipeline = Pipeline(stages=indexers + [assembler])\n",
        "df_dl = pipeline.fit(df_dl).transform(df_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sVhyAdxYreF"
      },
      "outputs": [],
      "source": [
        "#Se face conversia dintr-un DataFrame PySpark intr-un DataFrame Pandas\n",
        "pandas_df = df_dl.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE1nkBuWYwAx"
      },
      "outputs": [],
      "source": [
        "#Se creeaza variabla tinta, care va fi folosita pentru modelul de deep learning\n",
        "pandas_df['Player_1_Wins'] = (pandas_df['Winner'] == pandas_df['Player_1']).astype(int)\n",
        "\n",
        "#Sunt extrase coloanele din pandas_df din feature_cols\n",
        "#X va contine doar valorile numerice\n",
        "X = pandas_df[feature_cols].values\n",
        "\n",
        "#Se asigura ca nu exista coloana features in DataFrame\n",
        "if 'features' in pandas_df.columns:\n",
        "    X = pandas_df[feature_cols].values\n",
        "else:\n",
        "    X = pandas_df[[col for col in feature_cols if col in pandas_df.columns]].values\n",
        "\n",
        "#y este transformata in array pentru model\n",
        "#y va fi variabila tinta\n",
        "y = pandas_df['Player_1_Wins'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oywJiU14Y6JM"
      },
      "outputs": [],
      "source": [
        "#Setul de date este impartit in train_data, care este folosit pentru antrenarea modelului si test_data, care este folosit pentru evaluarea modelului\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICQYreM_Y7nF",
        "outputId": "a620f6d6-5da0-4e20-e4df-e11979dc0137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6214 - loss: 0.7573 - val_accuracy: 0.6108 - val_loss: 0.6663\n",
            "Epoch 2/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6217 - loss: 0.6884 - val_accuracy: 0.6603 - val_loss: 0.6194\n",
            "Epoch 3/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6317 - loss: 0.6565 - val_accuracy: 0.6504 - val_loss: 0.6444\n",
            "Epoch 4/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6406 - loss: 0.6447 - val_accuracy: 0.6639 - val_loss: 0.6197\n",
            "Epoch 5/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6436 - loss: 0.6343 - val_accuracy: 0.5843 - val_loss: 0.7305\n",
            "Epoch 6/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6429 - loss: 0.6362 - val_accuracy: 0.6559 - val_loss: 0.6237\n",
            "Epoch 7/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6476 - loss: 0.6247 - val_accuracy: 0.6450 - val_loss: 0.6226\n",
            "Epoch 8/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6495 - loss: 0.6274 - val_accuracy: 0.6622 - val_loss: 0.6155\n",
            "Epoch 9/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6542 - loss: 0.6220 - val_accuracy: 0.6626 - val_loss: 0.6145\n",
            "Epoch 10/10\n",
            "\u001b[1m1472/1472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6525 - loss: 0.6200 - val_accuracy: 0.6601 - val_loss: 0.6133\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6409 - loss: 0.6329\n",
            "Test Loss: 0.6276\n",
            "Test Accuracy: 0.6444\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        }
      ],
      "source": [
        "#Se creaza un model secvential Keras cu 3 straturi\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1],)),  #dimensiunea e data de numarul de coloane din X_train\n",
        "    layers.Dense(64, activation='relu'),      #strat cu 64 de neuroni si functia ReLU\n",
        "    layers.Dense(32, activation='relu'),      #al doilea strat cu 32 de neuroni\n",
        "    layers.Dense(1, activation='sigmoid')     #strat de iesire cu 1 neuron si activare sigmoida\n",
        "])\n",
        "\n",
        "#Modelul este compilat cu optimizer Adam, loss binary_crossentropy si acuratete ca metrica\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Modelul este antrenat cu 10 epoci\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "#Se calculeaza loss-ul si acuratetea si se afiseaza\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "#Se genereaza probabilitatile pentru fiecare exemplu din test\n",
        "predictions = model.predict(X_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTuIby//xkZkeisTxaE5Vv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}